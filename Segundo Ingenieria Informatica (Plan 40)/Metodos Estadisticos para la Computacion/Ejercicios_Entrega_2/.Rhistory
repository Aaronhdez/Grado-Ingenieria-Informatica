mediana_d<-median(Duracion)
cuantiles_d<-quantile(Duracion)
#APARTADO C
#Evaluar los parámetros de dispersión de la duración.
var_d<-var(Duracion)
sd_d<-sd(Duracion)
detach()
#APARTADO D
#Ordenar los países por semanas trabajadas.
datos_ord_semana<-datos[order(datos$Duracion),]
#APARTADO E
#Visualizar las diferencias con un diagrama de caja y distinguir
#los valores singulares. explicar
attach(datos_ord_semana)
boxplot(Duracion, notch = T,col = "Yellow",
ylab = "Media de jornada semanal",
xlab = "Paises en la UE")
grid()
abline(h=Duracion[Pais=="España"],col="blue",lwd=2, lty=2)
text(1.35,y=Duracion[Pais=="España"] +0.25,labels="España")
detach()
#APARTADO F
attach(datos_ord_pais)
par(mar=c(6,6,2,2)+0.1)
plot(1:nlevels(Pais), Duracion[Pais==levels(Pais)],
xaxt = "n", lwd =3, type="h", col="orange",
xlab="Pais_EU",
ylab="Duracion jornada semanal")
grid()
axis(side =1, at = 1:length(Pais), labels=F)
text(1:nlevels(Pais), par("usr")[3]-0.1,
labels=Pais, srt=30, pos=2, cex=0.6,
xpd = TRUE)
points(which(Pais=="España"), Duracion[Pais="España"], type="h",
col="green",lwd=3)
points(which(Pais=="España"), Duracion[Pais="España"], type="p",
col="green",lwd=3)
detach()
#APARTADO G (OPCIONAL)
#Revisar las horas trabajadas por semana en GRE, ESP Y GER (USAR $ -> NO ATACHAR DATOS)
horas_trabajo<-read.table("Archivos/H_T_A_UE_2017.txt", dec = ".", sep=",")
#Apartado H horas trabajadas(el fichero)/ semanas_trabajadas (OJO"ESP"-"España")
attach(horas_trabajo)
media_semanal_ESP<-as.numeric(horas_trabajo[horas_trabajo$Pais=="ESP",])/as.numeric(datos$Duracion[datos$Pais == "España"])
media_semanal_GRE<-as.numeric(horas_trabajo[horas_trabajo$Pais=="GRC",])/as.numeric(datos$Duracion[datos$Pais == "Grecia"])
media_semanal_GER<-as.numeric(horas_trabajo[horas_trabajo$Pais=="DEU",])/as.numeric(datos$Duracion[datos$Pais == "Alemania"])
data.frame(media_semanal_ESP,media_semanal_GER,media_semanal_GRE)
setwd(".")
library(knitr)
library(ggplot2)
library(sqldf)
library(DMwR2)
default<-read.table("Archivos/Puromicina.txt", dec = ".", sep=",",header=T)
#APARTADO A
#Media, mediana
attach(default)
media_VR<-aggregate(velocidad_reaccion~Puromicina,default,mean)
kable(media_VR)
mediana_VR<-aggregate(velocidad_reaccion~Puromicina,default,median)
kable(mediana_VR)
#APARTADO B
#parámetros de dispersión
varianza_VR<-aggregate(velocidad_reaccion~Puromicina,default,var)
kable(varianza_VR)
sd_VR<-aggregate(velocidad_reaccion~Puromicina,default,sd)
kable(sd_VR)
detach()
#APARTADO C
#Visualizar si la concetraciónde sustrato influye
#Datos sin ajuste.
attach(default)
plot(concentracion[Puromicina=="treated"],
velocidad_reaccion[Puromicina=="treated"],
col="red", pch=19)
grid()
points(concentracion[Puromicina=="untreated"],
velocidad_reaccion[Puromicina=="untreated"],
col="#037005", pch=19)
detach()
#Datos ajustados.
medias_datos<-aggregate(velocidad_reaccion~Puromicina+concentracion, default, mean)
kable(medias_datos)
attach(medias_datos)
plot(concentracion[Puromicina=="treated"],
velocidad_reaccion[Puromicina=="treated"],
col="red", pch=19)
grid()
points(concentracion[Puromicina=="untreated"],
velocidad_reaccion[Puromicina=="untreated"],
col="orange", pch=17)
#APARTADO D
datos_ord_velocidad<-default[order(default$velocidad_reaccion),]
kable(datos_ord_velocidad)
#APARTADO E
yt<-velocidad_reaccion[Puromicina=="treated"]
xt<-concentracion[Puromicina=="treated"]
modelo1<-lm(yt~xt+I(xt^(1/2)))
xv<-seq(from=0,to=1.1,by=0.01)
yv<-predict(modelo1,list(xt=xv))
lines(xv,yv, col="red", lwd=2)
yt2<-velocidad_reaccion[Puromicina=="untreated"]
xt2<-concentracion[Puromicina=="untreated"]
modelo2<-lm(yt2~xt2+I(xt2^(1/2)))
xv2<-seq(from=0, to=1.1, by=0.01)
yv2<-predict(modelo2, list(xt2=xv2))
lines(xv2,yv2, col="#ff8033", lwd=2)
detach()
# APARTADO F
datos_NA<-read.table("Archivos/Puromicina_NA.txt", dec = ".", sep=",", header=T)
kable(datos_NA)
# Completa los NA con un valor centralizado.
datos_ajustados<-centralImputation(datos_NA)
kable(datos_ajustados)
# Método del vecino mas cercano. Ajusta los NA al k mas cercano a ellos.
datos_ajustados_vecino<-knnImputation(datos_NA)
kable(datos_ajustados_vecino)
# Empleando NA.omit()
datos_ajustados_naomit<-na.omit(datos_NA)
kable(datos_ajustados_naomit)
# Empleado complete.cases()
datos_ajustados_cc<-datos_NA[complete.cases(datos_NA)==TRUE,]
kable(datos_ajustados_cc)
attach(datos_ajustados_naomit)
media_VR_naomit<-aggregate(velocidad_reaccion~Puromicina,datos_ajustados_naomit,mean)
kable(media_VR_naomit)
mediana_VR_naomit<-aggregate(velocidad_reaccion~Puromicina,datos_ajustados_naomit,median)
kable(mediana_VR_naomit)
detach()
attach(datos_ajustados_cc)
media_VR_cc<-aggregate(velocidad_reaccion~Puromicina,datos_ajustados_cc,mean)
kable(media_VR_cc)
mediana_VR_cc<-aggregate(velocidad_reaccion~Puromicina,datos_ajustados_cc,median)
kable(mediana_VR_cc)
detach()
#Creramos una tabl nueva con 0
datos_ceros<-datos_NA
datos_ceros$concentracion[is.na(datos_ceros$concentracion)]<-0
datos_ceros$velocidad_reaccion[is.na(datos_ceros$velocidad_reaccion)]<-0
kable(datos_ceros)
datos_ceros_knn<-knnImputation(datos_ceros)
# Resumenes de las tablas ajustadas
summary(datos_NA)
summary(datos_ajustados)
summary(datos_ajustados_vecino)
summary(datos_ajustados_naomit)
summary(datos_ajustados_cc)
summary(datos_ceros_knn)
setwd(".")
library(knitr)
library(ggplot2)
library(sqldf)
library(DMwR2)
#Binomial básica
n<-150
p<-0.02
mu<-n*p
sigma<-sqrt(n*p*(1-p))
#APARTADO A
#Analizar el tipo de función subyacente.
#APARTADO B
#Calcular la prob de que el numero de averías sea 5.
prob5<-dbinom(5,n,p)
#APARTADO C
#Encontrar la prob de que el numero de averías sea 3 o mas.
#Opción A con dbinom
prob3omas_db<-1-(dbinom(0,n,p)+dbinom(1,n,p)+dbinom(2,n,p))
#Opción B con pbinom
prob3omas_pb<-1-(pbinom(2,n,p))
#APARTADO D
#Tercer cuartil.
qr3<-qbinom(0.75,n,p)
#APARTADO E
#Numero minimo para que la probabilidad sea superior al 99%.
averiassup099<-log(0.99)/log(0.02)
#APARTADO F
#Calcular el percentil 95 de la distribución.
per95<-qbinom(0.95,n,p)
#APARTADO G
#Obtener una muestra de tamaño 1000 de la distribución.
set.seed(35200)
muestra<-rbinom(1000,n,p)
media_muestra<-mean(muestra)
sd_muestra<-sd(muestra)
hist(muestra, breaks=seq(-0.5,max(muestra+0.5)), col="lightblue", freq=F)
#APARTADO H
#Representar gráficamente el apartado G.
x<-seq(0,max(muestra)+1)
fx<-dbinom(x,n,p)
points(x,fx, type="b", col="red", lwd=2, pch=19)
abline(v=mu, col="darkblue", lwd=3)
setwd(".")
library(knitr)
library(ggplot2)
library(sqldf)
library(DMwR2)
#APARTADO A
#Calcular la probabilidad de que sea mayor o igual a 5.5
lambda<-3
p55<-ppois(5.5,lambda)
mu<-lambda
sigma<-sqrt(lambda)
#APARTADO B
px1y6_con1<-ppois(6,lambda)-ppois(0,lambda)
px1y6_sin1<-ppois(6,lambda)-ppois(1,lambda)
#APARTADO C
#Calcular el 5% de los valores mas bajos.
per75<-qpois(0.75,lambda)
#APARTADO D
#Calcular el 5% de los valores mas bajos.
per5<-qpois(0.05,lambda)
#APARTADO E
set.seed(35200)
sample<-rpois(500,3)
media_sample<-mean(sample)
sd_sample<-sd(sample)
hist(sample, breaks=seq(-0.5,max(sample+0.5)), col="lightblue", freq=F, add=F)
#APARTADO F
#Pillamos lambda por defect (3).
x<-seq(0,max(sample)+1)
x2<-seq(0,30)
fx<-dpois(x2,lambda)
fx2<-dpois(x2,2*lambda)
fx3<-dpois(x2,4*lambda)
plot(x2,fx3, col="red",type="b", lwd=2, pch=19)
points(x2,fx2, type="b", col="darkgreen", lwd=2, pch=19)
points(x2,fx, type="b", col="blue", lwd=2, pch=19)
plot(x2,fx3, col="red",type="b", lwd=2, pch=19, ylim=c(0,max(fx)))
points(x2,fx2, type="b", col="darkgreen", lwd=2, pch=19)
points(x2,fx, type="b", col="blue", lwd=2, pch=19)
grid()
plot(x2,fx3, col="red",type="b", lwd=2, pch=19, ylim=c(0,max(fx)))
points(x2,fx2, type="b", col="darkgreen", lwd=2, pch=19)
points(x2,fx, type="b", col="blue", lwd=2, pch=19)
setwd(".")
library(knitr)
library(ggplot2)
library(sqldf)
library(DMwR2)
#APARTADO A
#Calcular la probabilidad de que sea mayor o igual a 5.5
lambda<-3
p55<-ppois(5.5,lambda)
mu<-lambda
sigma<-sqrt(lambda)
#APARTADO B
px1y6_con1<-ppois(6,lambda)-ppois(0,lambda)
px1y6_sin1<-ppois(6,lambda)-ppois(1,lambda)
#APARTADO C
#Calcular el 5% de los valores mas bajos.
per75<-qpois(0.75,lambda)
#APARTADO D
#Calcular el 5% de los valores mas bajos.
per5<-qpois(0.05,lambda)
#APARTADO E
set.seed(35200)
sample<-rpois(500,3)
media_sample<-mean(sample)
sd_sample<-sd(sample)
hist(sample, breaks=seq(-0.5,max(sample+0.5)), col="lightblue", freq=F, add=F)
#APARTADO F
#Pillamos lambda por defect (3).
x<-seq(0,max(sample)+1)
x2<-seq(0,30)
fx<-dpois(x2,lambda)
fx2<-dpois(x2,2*lambda)
fx3<-dpois(x2,4*lambda)
grid()
plot(x2,fx3, col="red",type="b", lwd=2, pch=19, ylim=c(0,max(fx)))
points(x2,fx2, type="b", col="darkgreen", lwd=2, pch=19)
points(x2,fx, type="b", col="blue", lwd=2, pch=19)
setwd(".")
library(knitr)
library(ggplot2)
library(sqldf)
library(DMwR2)
#APARTADO A
#Calcular la probabilidad de que sea mayor o igual a 5.5
lambda<-3
p55<-ppois(5.5,lambda)
mu<-lambda
sigma<-sqrt(lambda)
#APARTADO B
px1y6_con1<-ppois(6,lambda)-ppois(0,lambda)
px1y6_sin1<-ppois(6,lambda)-ppois(1,lambda)
#APARTADO C
#Calcular el 5% de los valores mas bajos.
per75<-qpois(0.75,lambda)
#APARTADO D
#Calcular el 5% de los valores mas bajos.
per5<-qpois(0.05,lambda)
#APARTADO E
set.seed(35200)
sample<-rpois(500,3)
media_sample<-mean(sample)
sd_sample<-sd(sample)
hist(sample, breaks=seq(-0.5,max(sample+0.5)), col="lightblue", freq=F, add=F)
#APARTADO F
#Pillamos lambda por defect (3).
x<-seq(0,max(sample)+1)
x2<-seq(0,30)
fx<-dpois(x2,lambda)
fx2<-dpois(x2,2*lambda)
fx3<-dpois(x2,4*lambda)
plot(x2,fx3, col="red",type="b", lwd=2, pch=19, ylim=c(0,max(fx)))
points(x2,fx2, type="b", col="darkgreen", lwd=2, pch=19)
points(x2,fx, type="b", col="blue", lwd=2, pch=19)
grid()
setwd(".")
library(knitr)
library(ggplot2)
library(sqldf)
library(DMwR2)
library(e1071)
mu<-200
sigma<-250
#APARTADO A
Wdcha<-pnorm(250,200,25)
Wizq<-pnorm(200,200,25)
direfer<-Wdcha-Wizq
#APARTADO B
Px255<-1-pnorm(255,200,25)
#APARTADO C
#Percentil 95*percentil 5
p05<-qnorm(0.05,200,25)
p95<-qnorm(0.95,200,25)
#APARTADO D
#Generamos una muestra de 34600
set.seed(34600)
muestra<-rnorm(1000,200,25)
hist(muestra, freq=F, col="lightblue", density=25, ylim=c(0,2*max(Px255)))
abline(v=mean(muestra), col="blue",lwd=1)
#APARTADO E
x<-seq(min(muestra),max(muestra),0.1)
fx<-dnorm(x,200,25)
hist(muestra, freq=F, col="lightblue", density=25, ylim=c(0,max(fx)))
abline(v=mean(muestra), col="blue",lwd=1)
points(x,fx,col="red",lwd=0.5)
fhist<-hist(muestra, col="lightblue")
f_x<-cumsum(fhist$counts)/sum(fhist$counts)
x_ac<-fhist$breaks[2:length(fhist$breaks)]
plot(x_ac,f_x, type="h", lwd=2, col="green",
xlab="Cantidad", ylab="probabilidad")
grid()
f_xt<-pnorm(x_ac,200,25)
points(x_ac,f_xt,type="l",col="blue", lwd=2)
abline(h=direfer,col="red",lwd=3)
abline(h=Px255,col="brown", lwd=3)
#APARTADO F
skewness(muestra)
kurtosis(muestra)
#Es asimetrica muy ligeramente positiva y poco aplastada
#Mesocurtica
setwd(".")
library(knitr)
library(ggplot2)
library(sqldf)
library(DMwR2)
library(pyramid)
library(readxl)
#Leemos la tabla creada
poblacion <- read_excel("Archivos/E30260A_0023.xls", col_types = c("numeric", "numeric", "text", "text"))
attach(poblacion)
for(i in 2000:2018){
pyramid(as.data.frame(poblacion[Year==as.character((i)),1:3]),
Llab = "Hombres",
Rlab="Mujeres",
Clab = "Edades",
AxisFM = "d",
Laxis = seq(0,100000,30000),
Raxis = seq(0,100000,30000),
main= paste("Población Canarias",as.character((i))))
}
setwd(".")
library(knitr)
library(ggplot2)
germinacion<-read.table("Archivos/germination.csv", header=T, sep=",")
attach(germinacion)
#APARTADO A
n_germinadas<- sample - count
p_n_germinadas<- 100*(n_germinadas/sample)
germinacion<-cbind(germinacion,n_germinadas,p_n_germinadas)
attach(germinacion)
kable(germinacion[1:10,])
#APARTADO B
medias_n_g<-aggregate(p_n_germinadas~Orobanche+extract, germinacion, mean)
kable(medias_n_g)
boxplot(p_n_germinadas~Orobanche+extract,col="green")
#A73 judia
abline(h = medias_n_g[1,3], col="red", lwd="2")
#A75 judia
abline(h = medias_n_g[2,3], col="red", lwd="2")
#A73 pepino
abline(h = medias_n_g[3,3], col="red", lwd="2")
#A75 pepino
abline(h = medias_n_g[4,3], col="red", lwd="2")
grid()
#APARTADO C
#Judias
boxplot(p_n_germinadas[extract=="judia"]~Orobanche[extract=="judia"],
col="lightblue", ylim=c(0,100), xlab="genotipo")
modelo1<-lm(p_n_germinadas[extract=="judia"]~Orobanche[extract=="judia"])
abline(modelo1, col="blue", lwd=3)
text(1.5,50,labels="judia")
grid()
#Pepinos
boxplot(p_n_germinadas[extract=="pepino"]~Orobanche[extract=="pepino"],
col="orange", ylim=c(0,100), xlab="genotipo", add=T)
modelo1<-lm(p_n_germinadas[extract=="pepino"]~Orobanche[extract=="pepino"])
abline(modelo1, col="brown", lwd=3)
text(1,20,labels="pepino")
setwd(".")
library(knitr)
library(ggplot2)
library(mgcv)
empleo<-read.csv("Archivos/Empleos_Informatica_Canarias_2009-18.csv", sep=";")
attach(empleo)
######################################################
#APARTADO A
######################################################
#------------CAN 62------------#
CAN_62<-empleo[TRIMESTRES=="CNAE_62",2]
index<-seq(length(CAN_62),1,-1)
CAN_62_t<-CAN_62[index]
plot(1:length(CAN_62_t), CAN_62_t, xaxt="n", type="l",
xlab="Año", ylab="Personas Empladas CNAE:62",
ylim = c(0,max(CAN_62_t)),col="red", lwd=2)
years<-c("2009","2010","2011","2012","2013","2014","2015",
"2016","2017","2018")
axis(side=1, at = seq(1,length(CAN_62),4),
labels = years)
grid()
#GRAFICAS DE EMPLEO PARA GC Y TF
TFE_62<-TENERIFE[TRIMESTRES=="CNAE_62"]
GCA_62<-GRAN.CANARIA[TRIMESTRES=="CNAE_62"]
#PUNTOS PARA CADA UNA DE LAS ANTERIORES
points(1:length(CAN_62),TFE_62[index], type="l", col="blue",lwd=2)
points(1:length(CAN_62),GCA_62[index], type="l", col="yellow",lwd=2)
#------------CAN 63------------#
CAN_63<-empleo[TRIMESTRES=="CNAE_63",2]
index<-seq(length(CAN_63),1,-1)
CAN_63_t<-CAN_63[index]
plot(1:length(CAN_63_t), CAN_63_t, xaxt="n", type="l",
xlab="Año", ylab="Personas Empladas CNAE:63",
ylim = c(0,max(CAN_63_t)),col="red", lwd=2)
years<-c("2009","2010","2011","2012","2013","2014","2015",
"2016","2017","2018")
axis(side=1, at = seq(1,length(CAN_63),4),
labels = years)
grid()
#GRAFICAS DE EMPLEO PARA GC Y TF
TFE_63<-TENERIFE[TRIMESTRES=="CNAE_63"]
GCA_63<-GRAN.CANARIA[TRIMESTRES=="CNAE_63"]
#PUNTOS PARA CADA UNA DE LAS ANTERIORES
points(1:length(CAN_63),TFE_63[index], type="l", col="blue",lwd=2)
points(1:length(CAN_63),GCA_63[index], type="l", col="yellow",lwd=2)
#------------CAN 95------------#
CAN_95<-empleo[TRIMESTRES=="CNAE_95",2]
index<-seq(length(CAN_95),1,-1)
CAN_95_t<-CAN_95[index]
plot(1:length(CAN_95_t), CAN_95_t, xaxt="n", type="l",
xlab="Año", ylab="Personas Empladas CNAE:95",
ylim = c(0,max(CAN_95_t)),col="red", lwd=2)
years<-c("2009","2010","2011","2012","2013","2014","2015",
"2016","2017","2018")
axis(side=1, at = seq(1,length(CAN_95),4),
labels = years)
grid()
#GRAFICAS DE EMPLEO PARA GC Y TF
TFE_95<-TENERIFE[TRIMESTRES=="CNAE_95"]
GCA_95<-GRAN.CANARIA[TRIMESTRES=="CNAE_95"]
#PUNTOS PARA CADA UNA DE LAS ANTERIORES
points(1:length(CAN_95),TFE_95[index], type="l", col="blue",lwd=2)
points(1:length(CAN_95),GCA_95[index], type="l", col="yellow",lwd=2)
######################################################
#APARTADO B
######################################################
#Hecho para el CAN62.
#----------------- Grafica inicial -----------------#
y63<-CAN_63_t
x63<-seq(1,40)
y62<-CAN_62_t
x62<-seq(1,40)
y95<-CAN_95_t
x95<-seq(1,40)
plot(x63,y63, xlim=c(1,52), ylim=c(min(y63),2.5*max(y62)),
xlab="Predicción Empleo", ylab ="Numero de puestos", col="red", type="l", lwd=2)
points(x62,y62, type="l", col="orange", lwd=2)
points(x95,y95, type="l", col="blue", lwd=2)
#-----------------CAN 62-----------------#
x<-x62
y<-y62
modelogam62<-gam(y~s(x))
xv62<-(40:52)
yv62<-predict(modelogam62, list(x=xv62))
points(xv62,yv62, type="l", col="brown", lwd=2)
#-----------------CAN 63-----------------#
x<-x63
y<-y63
modelogam63<-gam(y~s(x))
xv63<-(40:52)
yv63<-predict(modelogam63,list(x=xv63))
points(xv63,yv63, type="l", col="pink", lwd=2)
#-----------------CAN 95-----------------#
x<-x95
y<-y95
modelogam95<-gam(y~s(x))
xv95<-(40:52)
yv95<-predict(modelogam95,list(x=xv95))
points(xv95,yv95, type="l", col="lightblue", lwd=2)
#-----------------FINAL -----------------#
abline(v=40, col="black", lwd=2, lty=2)
grid()
